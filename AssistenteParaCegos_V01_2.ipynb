{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVdnHc7gUA8TMbivSM9T66",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mario-Henrique/AssistenteParaCegos/blob/main/AssistenteParaCegos_V01_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realiza a instalação do pacote de ia do Google"
      ],
      "metadata": {
        "id": "k00foM5PCBH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YykRwy73BxPG"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurar a API_KEY do Gemini"
      ],
      "metadata": {
        "id": "LwiT8IvsCTCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n"
      ],
      "metadata": {
        "id": "kFsgq9mXCdQu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para saber quais os modelos disponíveis para uso então vamos listar todos."
      ],
      "metadata": {
        "id": "-KxGTXMDEZem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "k-w4SgeKEkc5",
        "outputId": "32df9e91-1a30-43cf-83d2-254eb9295ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determinar parâmetros de configuração do nosso modelo e\n",
        "Inicializar o modelo que será utilizado."
      ],
      "metadata": {
        "id": "AAUwY3HUD9Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.25\n",
        "}\n",
        "\n",
        "model_text = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
        "                              generation_config=generation_config)"
      ],
      "metadata": {
        "id": "_yNtw87wELsi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função responsável por receber um questionamento do usuário e retornar\n",
        "#a resposta do Assistente\n",
        "def GetAIResponse(question):\n",
        "  response = model_text.generate_content(question)\n",
        "\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "u20SvQL0GCLh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação do gTTS para sintetização do texto em voz e do\n",
        "pysoundfile para execução do audio"
      ],
      "metadata": {
        "id": "oeS3_VU1M34f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS\n",
        "!pip install pysoundfile"
      ],
      "metadata": {
        "id": "4r5dtyfzHY5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando a biblioteca IPython e gtts e criar a função responsável por falar um texto recebido."
      ],
      "metadata": {
        "id": "2yFRt2jLRlog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from gtts import gTTS\n",
        "\n",
        "def ReadText(text):\n",
        "  #Cria um objeto gtts\n",
        "  gtts_object = gTTS(text, lang='pt')\n",
        "\n",
        "  #Indica um caminho para salvar o arquivo gerado e salva o arquivo.\n",
        "  response_audio = \"/content/response_audio.mp3\"\n",
        "  gtts_object.save(response_audio)\n",
        "\n",
        "  #Toca o arquivo de leitura do texto\n",
        "  return IPython.display.Audio(response_audio, autoplay=True)"
      ],
      "metadata": {
        "id": "vA2TYukePSIX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função utilizada para tirar uma foto e descrever a cena."
      ],
      "metadata": {
        "id": "zl3T5H-fpWNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para efeito de exemplo aqui vou selecionar uma foto aleatoriamente porém a ideia seria realmente\n",
        "# tirar uma foto usando a câmera do gadget.\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import io\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "from random import randint\n",
        "\n",
        "# Nesse caso temos um parâmetro que indica que tipo de imagem será buscada.\n",
        "# Mas na função real não será necessário pois vai apenas tirar a foto e enviar ao Gemini\n",
        "def TakePhoto():\n",
        "  # Cria um array de exemplos onde a pessoa poderia estar\n",
        "  temas = ['Fachada de loja', 'praia movimentada', 'faixa de pedrestes', 'cesta de frutas', 'mesa com vários objetos']\n",
        "  palavra_chave = temas[randint(0, len(temas)-1)]\n",
        "\n",
        "  # Envia a requisição para o Google Images\n",
        "  response = requests.get(f\"https://www.google.com/search?q={palavra_chave}&tbm=isch\")\n",
        "\n",
        "  # Verifica se a requisição foi bem-sucedida\n",
        "  if response.status_code == 200:\n",
        "      # Extrai os URLs das imagens da página HTML\n",
        "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "      imagens = soup.find_all(\"img\", src=True)\n",
        "\n",
        "      index = randint(1, 5)\n",
        "      counter = 0\n",
        "      # Baixa e salva uma imagem aleatória\n",
        "      for imagem in imagens:\n",
        "          if counter < index:\n",
        "              counter = counter + 1\n",
        "              continue\n",
        "\n",
        "          url_imagem = imagem[\"src\"]\n",
        "          if url_imagem.startswith(\"data:image\"):\n",
        "              continue  # Ignora imagens em base64\n",
        "\n",
        "          response_imagem = requests.get(url_imagem, stream=True)\n",
        "          if response_imagem.status_code == 200:\n",
        "              Image.open(io.BytesIO(response_imagem.content)).convert('RGB').save(\"pic.jpg\")\n",
        "              break\n",
        "\n",
        "      # Criação da configuração do modelo\n",
        "      generation_config = {\n",
        "          \"candidate_count\": 1,\n",
        "          \"temperature\": 0.25\n",
        "      }\n",
        "      # Uma vez tendo a imagem vamos criar o modelo que aceita esse tipo de arquivo\n",
        "      model = genai.GenerativeModel(model_name=\"gemini-pro-vision\",\n",
        "                              generation_config=generation_config)\n",
        "\n",
        "      # Array com as imagens que podemos subir para o modelo\n",
        "      uploaded_files = []\n",
        "\n",
        "      # Função responsável por carregar as imagens no array\n",
        "      def upload_if_needed(pathname: str) -> list[str]:\n",
        "        path = Path(pathname)\n",
        "        hash_id = hashlib.sha256(path.read_bytes()).hexdigest()\n",
        "\n",
        "        try:\n",
        "          existing_file = genai.get_file(name=hash_id)\n",
        "          return [existing_file]\n",
        "        except:\n",
        "          pass\n",
        "        uploaded_files.append(genai.upload_file(path=path, display_name=hash_id))\n",
        "        return [uploaded_files[-1]]\n",
        "\n",
        "      prompt_model = [\n",
        "          \"Faça uma breve descrição dos elementos presentes na foto.\",\n",
        "          *upload_if_needed(\"pic.jpg\"),\n",
        "      ]\n",
        "\n",
        "      response = model.generate_content(prompt_model)\n",
        "\n",
        "      # Deleta a imagem\n",
        "      for uploaded_file in uploaded_files:\n",
        "        genai.delete_file(name=uploaded_file.name)\n",
        "\n",
        "      # Retorna a descrição da foto em caso de sucesso\n",
        "      return response.text\n",
        "  else:\n",
        "      # Imprime uma mensagem de erro\n",
        "      print(f\"Erro ao buscar imagens: {response.status_code}\")\n",
        "      return False"
      ],
      "metadata": {
        "id": "9V-X6rSLpfS5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conjunto de funções de utilidade que vamos usar para refinar e ajudar em nosso assistente"
      ],
      "metadata": {
        "id": "l-aSWJlPUrE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para dizer se uma palavra específica está no texto\n",
        "def contem_palavra(frase, palavra):\n",
        "  # Converter a frase e a palavra para minúsculas\n",
        "  frase_minuscula = frase.lower()\n",
        "  palavra_minuscula = palavra.lower()\n",
        "\n",
        "  # Verificar se a palavra está presente na frase\n",
        "  if palavra_minuscula in frase_minuscula:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "# Função que retorna True caso uma frase seja semelhante a outra em termos semânticos\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def comparar_textos(texto1, texto2):\n",
        "  # Criar um vetorizador TF-IDF\n",
        "  vectorizer = TfidfVectorizer()\n",
        "\n",
        "  # Transformar os textos em vetores de características TF-IDF\n",
        "  texto1_vetor = vectorizer.fit_transform([texto1])\n",
        "  texto2_vetor = vectorizer.transform([texto2])\n",
        "\n",
        "  # Calcular a similaridade cosine entre os vetores\n",
        "  similaridade = cosine_similarity(texto1_vetor, texto2_vetor)[0][0]\n",
        "\n",
        "  # Definir um limiar de similaridade\n",
        "  limiar = 0.65  # Valor entre 0 e 1, quanto maior, mais rigorosa a comparação\n",
        "\n",
        "  # Retornar True se a similaridade for maior que o limiar, False caso contrário\n",
        "  return similaridade >= limiar"
      ],
      "metadata": {
        "id": "f_xQs9kAUzRN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação do SpeechRecognition para transcrição de aúdio."
      ],
      "metadata": {
        "id": "qG18_gXBYFhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "id": "f_qrKwcrYJr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capturar aúdio do microfone, verificar se é um comando e realizar a ação necessária!"
      ],
      "metadata": {
        "id": "jJNOh538TF8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# Definir a taxa de amostragem e o número de canais de áudio\n",
        "CHUNK = 1024\n",
        "RATE = 44100\n",
        "\n",
        "# Inicializar o recognizer do Google Speech Recognition\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Configurar o microfone como fonte de entrada\n",
        "mic = sr.Microphone()\n",
        "\n",
        "with mic as source:\n",
        "    # Ajustar o nível de ruído do ambiente (opcional)\n",
        "    recognizer.adjust_for_ambient_noise(source)\n",
        "\n",
        "    # Informar ao usuário que a gravação está iniciando\n",
        "    print(\"Aguardando voz...\")\n",
        "\n",
        "    # Gravar o áudio do microfone\n",
        "    audio = recognizer.listen(source, chunk_length=CHUNK)\n",
        "\n",
        "try:\n",
        "    # Reconhecer a fala no áudio gravado\n",
        "    texto = recognizer.recognize_google(audio, language='pt-BR')\n",
        "\n",
        "    if contem_palavra(texto, \"Assistente\"):\n",
        "      if comparar_textos(\"O que você está vendo?\", texto):\n",
        "        ReadText(TakePhoto())\n",
        "      else:\n",
        "        ReadText(GetAIResponse(texto))\n",
        "\n",
        "except sr.UnknownValueError:\n",
        "    print(\"Não entendi o que você disse.\")\n",
        "except sr.RequestError as e:\n",
        "    print(\"Ocorreu um erro: {0}\".format(e))"
      ],
      "metadata": {
        "id": "izvzDa8FTlhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testando geração de texto com o Gemini e usando recurso de fala.\n",
        "response = GetAIResponse('De forma direta me diga o que é criatividade?')\n",
        "ReadText(response)"
      ],
      "metadata": {
        "id": "ipOUjy3e-Xl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando recurso de descrever o que a pessoa \"poderia estar vendo\".\n",
        "response = TakePhoto()\n",
        "ReadText(response)"
      ],
      "metadata": {
        "id": "47-5uovY9kKx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}